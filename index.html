<html>

<marquee> Parikshit Molkar </marquee>
    
<pre>    
Parikshit Molkar
Ph#: (470) 912 8288
LinkedIn: www.linkedin.com/in/parikshit-molkar
Email: pmolkar@gmail.com	

Profile

Self driven, passionate and seasoned Data and Analytics Cloud Engineer with over 20 years of experience in delivering complex big data transformations. Specializing in cutting-edge technologies such as Azure, Hadoop, Spark, Kafka and data warehousing techniques like data mesh and data products, I excel in architecting and implementing data warehouses, data lakes and lake-houses to drive operational efficiency and unlock actionable insights. Known for innovative problem-solving, complex stakeholder engagement, and a passion for AI, I thrive in dynamic environments and consistently pursue process excellence.

Key Competencies

Technical Skills:

Cloud Platforms: Azure
Big Data Technologies: Hadoop, Apache Spark, Hive, Kafka
Data Modeling Methodologies: Data Vault 2.0, Kimball (Star Schema), 3NF
Databases: Teradata, Oracle
Programming Languages: SQL, Python
Tools: Siebel CRM, Power BI, PowerApps, Erwin, Confluence, JIRA
Methodologies: Agile, Six Sigma, Design Thinking and Experimentation
Business Domains: Banking and Financial Services, Healthcare, Retail, HR.

Design and Delivery:

    • Specialist in data mesh and data product strategy implementation to transform the data platform, aligning with industry best practices.
    • Designed and Implemented end-to-end big data cloud solutions for complex initiatives like financial crime, ensuring compliance with regulatory standards.
    • Modeled and delivered complex data structures using Data Vault 2.0, Teradata FS LDM, and Oracle ECDM.

Stakeholder Management:

    • Negotiation with senior stakeholders like CTO, Chief Engineers, and Data Governance teams to endorse proposed solutions.
    • Managed escalations and delivery timelines, ensuring project success.

Innovation and Technical Proficiency:

    • Conducted POC’s to assess vendor tools for organisations suitability.

Professional Experience

Westpac Banking Corporation
Portfolio Solutions Designer	 			AUS, June 2021 – May 2024

Commonwealth Bank of Australia
Application Architect					AUS, April 2014 – June 2021

Westpac Banking Corporation @ TCS
Oracle BI Tech Lead 					AUS, 2012 – 2014
Siebel CRM Tech Lead					AUS, 2010 – 2012

GE Healthcare @ TCS					USA, 2003 – 2010
Siebel CRM Tech Lead

HR @ TCS							INDIA, 2002 – 2003
Oracle PL/ SQL Developer 

Somerfield UK @ TCS					INDIA, 2001 - 2002
Mainframe Developer


Qualifications and Skills

Education:

Bachelor of Engineering, Mumbai University, 2000
Post Graduate Diploma in Advanced Computing, CDAC, 2001

Certifications:

Six Sigma Green Belt Certified
Design Thinking and Experimentation Coach




Career Summary

Westpac Banking Corporation
Portfolio Solutions Designer, Sydney				June 2021 – May 2024

Achievements:

    • Architected and designed innovative data mesh and data product strategy for the banks big data platform (DDEP) consisting of over 2,000 datasets spanning 400+ source systems.
    • Spearheaded the data products implementation on the Azure IaaS platform, leveraging Hadoop, Hive, Apache SPARK and Apache Ranger.
    • Provided consultation for migration of Azure IaaS to PaaS using ADLS2, Azure Synapse, Azure Cosmos DB and Azure Data Factory.
    • Designed and delivered ETL pipeline framework capabilities to enable SCD2.
    • Designed and delivered ingestion of reference data from the banks reference data application – Enterprise Reference Data Management (ERDM) to build the ERD FDP, which is a key enabler to conform data across all data products.
    • Designed and implemented a robust RBAC security model for the data product implementation using Apache Ranger.
    • Build complex transformation routines using python scripts to categorize transactions as per business requirements for the transaction categorization (transcat) program.
    • Designed and developed robust Erwin data models including Conceptual, Logical and Physical (CDM, LDM and PDM) Models to support data products in alignment with Oracle ECDM.Designed and implemented Key Management Repository (KMR) to obscure sensitive key elements in datasets while maintaining the referential integrity.
    • Designed and developed scalable and efficient data pipelines using Pyspark for processing and transforming large data volumes. 
    • Provided technical leadership and expert guidance to delivery teams, ensuring high quality of delivery.
    • Responsible for end to end design and delivery of key data products like ATM, Branch, Customer Cortex (360), Enterprise Reference Data (ERD), Financial Crime (Fincrime) and Transaction categorization (Transcat).
    • Reviewed and approved documents like Business Requirements Document (BRD), Test Strategy for large complex initiatives.
    • Interviewed and mentored new team members, fostering a culture of continuous learning and development.



Commonwealth Bank of Australia
Application Architect, Sydney					April 2014 – June 2021

Achievements:

    • Delivered End to End big data platform solutions for large programs like Financial Crime, Open Banking, and Smarter Banking, etc.
    • Designed and delivered data models for Data Vault 2.0, simplifying data lake implementation to align with the townplan.
    • Performance tuning of jobs to meet the delivery, platform and resource requirements.
    • Converted high level architecture documents into detailed technical solutions for delivery teams to implement.
    • Produced TEP estimates for large programs of work to be submitted to program management teams for approval.
    • Performed impact analysis and provided forecast growth estimates for platform requirements.
    • Collaborated with Project Management teams as the senior advisor on the squad to deliver best in class solutions.
    • Provided technical leadership and expert guidance to development teams, ensuring adherence to architectural standards and best practices.
    • Conducted code reviews, performance optimizations, and troubleshooting to maintain high-quality software solutions.
    • Proposed and developed a Data Profiling framework for the platform.
    • Proposed and implemented a control framework for ETL pipelines.
    • Developed reusable data pipeline templates, reducing delivery effort and cost.




</pre>
</html>
